{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as cv\n",
    "import sklearn.ensemble        as ensem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifierCV(ensem.RandomForestClassifier):\n",
    "    '''\n",
    "        This class implements cross validation *ONLY* for the \n",
    "        number of estimators. It does this using OOB scoring and\n",
    "        warm starts. In theory this should be doable in sk-learn by\n",
    "        default, but I am unable to make it work without this\n",
    "        roll-you-own solution\n",
    "        \n",
    "        Note: always computes up to max_estimators. Then picks the\n",
    "        smallest possible within the tolerance. There are presumably\n",
    "        better ways to detect stabilization.\n",
    "        \n",
    "        For other hyperparemeters, use GridSearch, below\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_estimators = 500, tolerance = 0.005, **kwargs):\n",
    "        kwargs['warm_start']   = True\n",
    "        kwargs['oob_score']    = True\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_estimators = max_estimators\n",
    "        self.tolerance      = tolerance\n",
    "        self.use_oob_score  = True\n",
    "        self.init_kwargs    = kwargs\n",
    "        \n",
    "    def reset_and_clone(self):\n",
    "        return RandomForestClassifierCV(max_estimators = self.max_estimators,\n",
    "                                        tolerance      = self.tolerance, \n",
    "                                       **self.init_kwargs)\n",
    "        \n",
    "    def score(self, *args, **kwargs):\n",
    "        if self.use_oob_score:\n",
    "            return self.best_score\n",
    "        else:\n",
    "            return super().score(*args, **kwargs)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n_est_scores_ = {}\n",
    "        for i in range(100, self.max_estimators + 1, 100):\n",
    "            self.n_estimators = i\n",
    "            super().fit(X, y)\n",
    "            self.n_est_scores_[i] = self.oob_score_\n",
    "            \n",
    "        self.best_score = max(self.n_est_scores_.values())\n",
    "        self.best_n     = next(n for n, v in self.n_est_scores_.items() if v > self.best_score - self.tolerance)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def finalize(self, X, y):\n",
    "        self.use_oob_score = False\n",
    "        \n",
    "        self.set_params(warm_start = False)\n",
    "        \n",
    "        self.n_estimators = self.best_n\n",
    "        super().fit(X, y)\n",
    "        \n",
    "    def get_params(self, *args, **kwargs):\n",
    "        out = ensem.RandomForestClassifier().get_params()\n",
    "        out['max_estimators'] = self.max_estimators\n",
    "        out['tolerance']      = self.tolerance\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch():\n",
    "    '''\n",
    "        Grid Search *without* cross validation.\n",
    "        Doesn't implement full feature set of GridSearch\n",
    "        \n",
    "        Just fit, predict in a bare-bones fashion\n",
    "        \n",
    "        Designed for use with RandomForestCV above\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, estimator, param_grid, verbose = 0):\n",
    "        self.param_grid       = cv.ParameterGrid(param_grid)\n",
    "        self.parent_estimator = estimator\n",
    "        self.verbose          = verbose\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.best_params = None\n",
    "        self.best_model  = None\n",
    "        self.best_score  = 0\n",
    "        \n",
    "        progress_count   = 0\n",
    "        if self.verbose:\n",
    "            print(f'{len(self.param_grid)} Iterations to do')\n",
    "        Timer.start()\n",
    "        \n",
    "        for param_dict in self.param_grid:\n",
    "            model = self.parent_estimator.reset_and_clone()\n",
    "            model.set_params(**param_dict)\n",
    "            model.fit(X, y)\n",
    "            \n",
    "            if model.score() > self.best_score:\n",
    "                self.best_params = param_dict\n",
    "                self.best_model  = model\n",
    "                self.best_score  = model.score()\n",
    "                \n",
    "            progress_count += 1\n",
    "            if self.verbose and progress_count % 20 == 0:\n",
    "                print(f'{progress_count} Done')\n",
    "                Timer.end()\n",
    "        \n",
    "        # This fails if every model somehow had an accuracy of 0...\n",
    "        assert bool(self.best_params)\n",
    "        \n",
    "        self.best_model.finalize(X, y)\n",
    "        \n",
    "        return self.best_model\n",
    "        \n",
    "    def predict(self, *args, **kwargs):\n",
    "        return self.best_model.predict(*args, **kwargs)\n",
    "    \n",
    "    def score(self, *args, **kwargs):\n",
    "        return self.best_model.score(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
